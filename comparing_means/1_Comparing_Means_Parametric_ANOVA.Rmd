---
title: "Comparing Means - ANOVA"
author: "Felix Eßer"
date: "10/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Analysis of Variance (ANOVA) is a family of analyses to compare the mean of several samples. Hence, the outcome variable has at least to be metric scale of measurement and the predictor variable(s) has/have nominal scale of measurement.

In the context of ANOVA, the predictor is often called factor or independent variable (note that independent variable implies causal influence). Factors have levels which are also called conditions. For example, in a clinical study it is of interest how a new drug influences the blood pressure of patients. To assess the efficacy of the new drug it is compared to an old drug as well as a placebo. The factor *drug* in this study has three levels: 1) new drug, 2) old drug and 3) placebo. After assigning participants randomly to one of the three levels, administering the corresponding drug and measure the blood pressure, it is possible to compare the means of all blood pressures in the three conditions with a ANOVA. 


One-way ANOVA with factor of 3 levels.

Another factor gender can be added. Then a two-way ANOVA with a 3x2 design (3 levels of factor drug and 2 levels of factor gender)

Different kinds of designs: 
- 1 factor: one-way ANOVA 
- 2 factors: two-way ANOVA 
- and so on

It is also possible that a factor comprises dependent samples. A typical reason are repeated measures of the same cases.

$F$-test is an omnibus test (global test) Follow up with contrast analysis or post-hoc tests

The different kinds of ANOVA are presented in the following way: 
1. Comparing several independent samples 
        + One-way ANOVA 
            e.g., the aforementioned example of the influence of different drugs on blood pressure
        + Two-way ANOVA 
            e.g., th
2. Comparing several dependent samples 
        + One-way ANOVA for dependent samples
        + Two-way ANOVA for dependent samples
3. Comparing independent and dependent samples

fixed and random effects 
+ fixed effects - factor has fixed values - means of the factor levels are of interest + random effects - factor levels are a random draw of several possible manifestations of the factor - variance of the means of the factor levels is of interest + distinction has no consquence for one-way ANOVA but for two-way ANOVA



$\alpha$-error cumulation

Two approaches as follow-up analysis after a significant $F$-test: 1. Post-hoc tests 2. Contrasts analysis

## Post-hoc tests

Post-hoc tests compare means of different factor levels.

To avoid $\alpha$-error cumulation, there are two common procedures: 
1. Adjustment of the $\alpha$-error of specific comparisons 
        + typically used if only selected mean comparisons are of interest
2. Adjustment of the critical values for multiple comparisons
        + typically used if all possible comparisons are of interest

There are a lot of procedures for post-hoc test.

### Adjustment of the $\alpha$-error of specific comparisons

1.  Sidak Adjustment
2.  Bonferroni Adjustment
3.  Bonferroni-Holm Adjustment

### Adjustment of the critical values for multiple comparisons

1.  Tukey-Test and Tukey-Kramer-Test Tukey-test is also known as HSD-test: Honest-Significant-Difference-test. Tukey-test is requires balanced sample sizes, whereas the Tukey-Kramer-test allows for differing sample sizes.

Has more power than bonferroni-correction if all means are compared with each other.

2.  Dunnett-Tes

## Contrast analysis

+-----------------------+---------------------------------------------------------------+------+
| Name of contrasts     | Explanation                                                   | Col3 |
|                       |                                                               |      |
| (R Code)              |                                                               |      |
+=======================+===============================================================+======+
| Dummy (default)       | Each factor level is compared to the first factor level.      |      |
+-----------------------+---------------------------------------------------------------+------+
| SAS                   | Each factor level is compared to the last factor level.       |      |
|                       |                                                               |      |
| (`contr.SAS()`)       |                                                               |      |
+-----------------------+---------------------------------------------------------------+------+
| Treatment             | Each factor level is compared to a user defined factor level. |      |
|                       |                                                               |      |
| (`contr.treatment()`) |                                                               |      |
+-----------------------+---------------------------------------------------------------+------+
| Sum                   |                                                               |      |
|                       |                                                               |      |
| (`contr.sum()`)       |                                                               |      |
+-----------------------+---------------------------------------------------------------+------+
| Helmert               |                                                               |      |
|                       |                                                               |      |
| (`contr.helmert()`)   |                                                               |      |
+-----------------------+---------------------------------------------------------------+------+
| Poly                  |                                                               |      |
|                       |                                                               |      |
| (`contr.poly()`)      |                                                               |      |
+-----------------------+---------------------------------------------------------------+------+

: Predefined Contrasts in \`R\`


### $\alpha$-error cumulation

Scheffé test

# Packages

```{r packages}
library(afex) # ANOVA
library(car) # Levene Test
library(effectsize) # omega^2
library(emmeans) # estimate marginal means
library(multcomp) # control for alpha error in multiple testing
library(skimr) # descriptive statistics
library(tidyverse) # data wrangling and plotting

# The afex package requires MASS which has a select function
# In order to use the dplyr select function by default:
select <- dplyr::select
```

# Comparing several independent samples

## One-way ANOVA

### Theory of one-Way ANOVA

The one-way ANOVA is a extension of the $t$-test.

Only an omnibus test:

Null-hypothesis: $H_0: \mu_i = \mu_j$ for all pairs \$(i, j),\~\~i \neq j \$ Alternative hypothesis: $H_1: \neg H_0$

This hypothesis is tested via a $F$-test (always one-sided). If the null-hypothesis has to be rejected, it can only be derived **that** means differ but not which.

Effect Size $\hat{\eta}^2 = \frac{SS_B}{SS_T}$ (see appendix for explanation). However, this

#### Assumptions of one-way ANOVA

1.  Independent residuals + residuals are independent from another + this assumption is fulfilled via the research design + is for example violated through repeated measures + violation increases hugely probability of committing an $\alpha$ error

2.  Homoskedasticity + Equal variance of residuals between conditions + is tested with Levene's test for equal variances + The $F$-test is relatively robust against violations of the assumption of homoskedasticity if samples have the same size - if variance in smaller sample is larger than in a larger sample, the $F$-test becomes too liberal (higher risk of committing an $\alpha$ error) - if variance in smaller sample is smaller than in a larger sample, the $F$-test becomes too conservative (higher risk of committing an $\beta$ error) + If there is variance heterogeneity (heteroskedasticity), the Brown-Forsythe-test or the Welch-test can be used which correct the result. No one of both is superior to the other.

3.  Normal distribution of residuals\

    -   As a residuum is the deviation of a measurement from the mean of the condition, measurements have to distribute normally within conditions + On the basis of the central limit theorem, the $F$-test is relatively robust against violations against the normality assumption under large sample sizes. So you can argue this assumption away. + If the violation of the normality assumption is due to outliers, robust variants of ANOVA can be conducted.

### Data

```{r indep1-data}
# load data
data_indep1 <- datasets::PlantGrowth %>% 
    as_tibble() %>% # convert data.frame to tibble
    rowid_to_column("ID") # adding ID variable

# get descriptives
skim(data_indep1)
```

In the dataset `data_indep1` the weight of plants is measured under three different conditions. Each condition comprises ten plants.

```{r indep1-descr}
# Get descriptive statistics per group
data_indep1 %>% 
    select(-ID) %>% # discard ID variable
    group_by(group) %>% # group output by grouping variable 'group'
    skim() # get descriptive statistics
```

As shown in the output the mean weight in the control group is `r mean(filter(data_indep1, group == "ctrl")$weight)`, in the first treatment group `r mean(filter(data_indep1, group == "trt1")$weight)` and in the second treatment group `r mean(filter(data_indep1, group == "trt2")$weight)`. The question which is possible to answer with the one-way ANOVA is, whether these means differ significantly or differ by chance.

### Assessing assumptions of one-way ANOVA

1.  Independent residuals + residuals are independent from another + this assumption is fulfilled via the research design + is for example violated through repeated measures
2.  Homoskedasticity

```{r indep1-levene-test}
leveneTest(weight ~ group, data = data_indep1)
```

3.  Normal distribution of residuals\

    -   As a residuum is the deviation of a measurement from the mean of the condition, measurements have to distribute normally within conditions
    
```{r indep1-shapiro-test}
# Calculate shapiro wilk test for each group
tapply(data_indep1$weight, data_indep1$group, shapiro.test)
```
    

### One-way ANOVA analysis with `{stats}`

One-way ANOVA can be conducted with the `aov()` function of the `{stats}` package.

```{r indep1-anova-aov}
# Perform one-way ANOVA
anova_aov <- aov(weight ~ group, data = data_indep1)

# Get results
summary(anova_aov) # same as: anova(anova_aov)
```

Note that the ANOVA can be reframed as a linear model. In this case the three factor level will be coded into two dummy variables (number of dummy variables = $k -1$, where $k$ is the number of levels). In this way the one-way ANOVA can be computed via the `lm()` function of the `{stats}` package.

```{r indep1-anova-lm}
# Perform one-way ANOVA with lm()
anova_lm <- lm(weight ~ group, data = data_indep1)

# Get results
summary(anova_lm)
```

The estimate of the intercept represents the mean of the reference group (here control group). The estimates of the other coefficients are the respective difference of the corresponding group to the reference group.

Both, the `aov()` and the `lm()` function, calculate the same model but the results are presented differently.

It is possible to transform the `aov()` output into the `lm()` output and vice versa.

```{r indep1-anova-aov-to-lm}
# Transform aov() output into lm() output
summary.lm(anova_aov)

# Transform lm() output into aov() output
summary.aov(anova_lm) # same as anova(anova_lm)

```

A better function is the `oneway.test()` function of the `{stats}` package because it corrects for unequal variances.

```{r indep1-anova-oneway}
# Performing one-way ANOVA without assuming equal variances
oneway.test(weight ~ group, data = data_indep1)
```

### One-way ANOVA analysis with `{afex}`

```{r indep1-anova-afex}
# Perform one-way ANOVA with afex-package
anova_afex <- aov_ez(id = "ID", dv = "weight", between = "group",
                     data = data_indep1)

# Get results
summary(anova_afex)
```

### Contrasts

#### Contrasts with `{stats}`

Set contrasts as attribute to the factor in the `data.frame`

```{r}
contrasts(data_indep1$group) <-  contr.helmert(3) # 3 groups / levels of factor
```

### Post-hoc Tests

#### Adjustment of the $\alpha$-error of specific comparisons

```{r}
pairwise.t.test(data_indep1$weight, data_indep1$group,
                p.adjust.method = "bonferroni",
                alternative = "two.sided") # default: two.sided 
```

Available $p$-value adjustments in the base `R` `{stats}` package: 1. holm 2. hochberg 3. hommel 4. bonferroni 5. BH (Benjamini & Hochberg) --\> controls for false discovery rate 6. fdr = same as BH 7. Benjamini, Hochberg, and Yekutieli --\> controls for false discovery rate

#### Adjustment of the critical values for multiple comparisons

Use `TukeyHSD()` function from `{stats}` package

```{r}
TukeyHSD(anova_aov)
```

### Report

Add ANOVA table (SS, df, MS, F, p, eta\^2 or omega\^2) Often the row with the total variation is ommited because it can be derived from the other sources of variance.

Report in text:

Visualization with bar diagram with error bars (either sd, se or ci)

## Two-Way ANOVA

### Theory of two-way ANOVA

main effects and interaction effects

simple effects
- 


marginal means 


# Comparing several dependent samples

## One-way ANOVA for dependent samples

### Theory of one-way ANOVA for dependent samples

It is possible to use ANOVA for repeated measures designs or other designs in which the groups under study are dependent (e.g., siblings). In general, this analysis is used for within-subject designs in which a dependent variable is measured several times on subjects.

Hypothesis: Means of all related samples/groups are equal: $H_0: $

sequence effects -> create link to *research methods*

### Data

```{r}
data_dep <- datasets::Orange %>% 
    mutate(tree = factor(Tree, ordered = FALSE),
           measurement = factor(age, labels = seq(unique(age)))) %>% 
    select(tree, measurement, circumference)
    
glimpse(data_dep)    
```

### Assumptions of ANOVA for several dependent groups

-   Assumption of sphericity

    -   The variances of the differences between all pairs of conditions (repeated measures) have to be equal.
    -   This assumption is sometimes called circularity assumption.
    -   If this assumption is violated the $F$-statistic is to liberal (too many false positive results)

-   Assumption of normally distributed residuals

$$SS_T~~=~~SS_{BP}~+ \underbrace{SS_{WP}}_{SS_M + SS_R}$$

(a less restrictive form of compound symmetry, which assumes that the variances of the differences between data taken from the same participant (or other entity being tested) are equal. This assumption is most commonly found in repeated-measures ANOVA but applies only where there are more than two points of data from the same participant (see also Greenhouse--Geisser correction, Huynh--Feldt correction).)

#### Testing the Assumptions of ANOVA for several dependent groups

The assumption of sphericity can be tested with Mauchly's test. Mauchly's test tests the hypothesis that the variances of the differences between all pairs of conditions are equal. The statistic distributes approximately as a $\chi^2$ distribution with $k$-1 degrees of freedom ($k$ = number of dependent samples). However this test is often very strict (liberal), meaning it becomes significant when the normality assumption is violated.

Index $\varepsilon_{Box}$ is a index indicating how much the covariance-matrix of the population deviates from sphericity. This index varies between $\frac{1}{k-1}$ and 1, where $k$ is the number of repeated conditions. If $\varepsilon_{Box} = 1$ the matrix shows perfect sphericity. $\varepsilon_{Box}$ can be estimated via different methods which lead to different corrections of the degrees of freedom of the $F$-test.

If the assumption of sphericity does not hold, there are two commonly known correction methods: 1. Greenhouse-Geiser correction (Greenhouse & Geisser, 1959) - The Greenhouse-Geiser correction $\hat{\varepsilon}$ varies between $\frac{1}{k-1}$ and 1, where $k$ is the number of repeated conditions. - The closer $\hat{\varepsilon}$ is to 1, the more homogeneous the differences of variances are. - Multiplication of $\hat{\varepsilon}$ with the degrees of freedom of the critical $F$ statistic - In general, if $\hat{\varepsilon} < .75$, then the sphericity assumption is violated. - If $\hat{\varepsilon} > .75$, the Greenhouse-Geiser correction is too conservative, meaning too many false null hypotheses are not rejected ( $\beta$-error; Huynh & Feldt, 1976) 2. Huynh-Feldth correction (Huynh & Feldt, 1976) - the Huyn-Feldth correction $\tilde{\varepsilon}$ varies between ... and ... - uses $\hat{\varepsilon}$ and corrects it - $\tilde{\varepsilon}$ is greater than $\hat{\varepsilon}$, which results in a smaller correction - $\tilde{\varepsilon}$ overestimates sphericity (Maxwell & Delaney, 1990)

Also possible to model dependent data within a multilevel modeling framework.

### Dependent Samples ANOVA with `{stats}`

```{r}
dep_anova <- aov(circumference ~ measurement + Error(tree), data = data_dep)

```

### Dependent Samples ANOVA with `{afex}`

```{r}
library(afex)
data_dep2 <- afex::obk.long

dep_anova2 <- aov_ez(id = "id", dv = "value", data = data_dep2, within = "phase")
summary(dep_anova2)

```

Mauchly's test resulted in a non-significant value, \$\chi\^2(2) = 0.7

### Effect Sizes

### Contrasts

### Post hoc tests

### Visualizing the results

## Two-way ANOVA for dependent samples

```{r}
# simulate data of a 2x2 design with repeated measues on both factors

# totally 10 people were measured:
persons <- tibble(ID = rep(1:10, each = 9),
                  measurement = gl(3, 3, 90, labels = c("pre", "post", "followUp")),
                  within_measurement = gl(3, 1, 90, labels = c("first", "second", "third")))

# simulate dv only dependent on pre post
set.seed(63938)
dv <- tibble(ID = rep(1:10, each = 3),
             pre = rnorm(30, mean = 10, sd = 1),
             post = rnorm(30, mean = 12, sd = 1),
             followUp = rnorm(30, mean = 14, sd = 1)) %>% 
    pivot_longer(cols = c(pre, post, followUp), names_to = "measurement",
                 names_transform = list(measurement = as.factor)) %>% 
    mutate(within_measurement = gl(3,3,90, labels = c("first", "second", "third")))

sim_data <- persons %>% 
    full_join(dv, by = c("ID", "measurement", "within_measurement"))


two_rep <- aov_ez(id = "ID", dv = "value", within = c("measurement", "within_measurement"), data = sim_data)
two_rep
summary(two_rep)


# marginal means
    # marginal means are model based 
ref_grid(two_rep)

marginal_measurement <- emmeans(two_rep, ~ measurement)
marginal_measurement@grid # get weights

marginal_measurement
pairs(marginal_measurement)


afex_plot(two_rep, x = "measurement", trace = "within_measurement", error = "within")

```

### Post-hoc tests

```{r}
pairwise.t.test()
```

# Comparing independent and dependent samples

```{r}
datasets::sleep
```

## Assumptions

-   Sphericity of the dependent factor
-   equality of variance in the independent factor

```{r}
library(afex)
library(emmeans)
data_dep2 <- afex::obk.long
data_dep2
mix_anova <- aov_ez(id = "id", dv = "value", data = data_dep2, within = "phase", between = "treatment",
                    anova_table = list(es = "pes"))
mix_anova <- aov_ez(id = "id", dv = "value", data = data_dep2, within = "phase", between = "treatment")
summary(mix_anova)
mix_anova


# obtain emmGrid-class
em_mix_anova <- emmeans(mix_anova, ~treatment)

pairs(em_mix_anova)
```

# Appendix: Theory and Mathematics of ANOVA

## Comparing several independent samples

### One-way ANOVA

Indices: Conditions: $k$ = 1, .., $K$ Cases: $n$ = 1, ..., $N$

Composition of the measurement $y_{nk}$ of case $n$ which is in condition $k$ in two kinds of variation: $$ y_{nk} = \overline{y}_k + (y_{nk} - \overline{y}_k) = \overline{y}_k + e_{nk}$$,

where $\overline{y}_k$ is the mean of the condition (factor level) and $e_{nk}$ is the deviation of case $n$ from the mean of condition $k$.

Composition of the mean of the condition: $$ t_j =  \overline{y}_k - \overline{y}$$,

where $t_j$ is the treatment effect and $\overline{y}$ is the grand mean. The grand mean is the mean over all values irrespective a any condition. For unbalanced data (different group sizes) the grand mean is calculated by: $$ \overline{y} = \Sigma_{k = 1}^K \frac{N_j}{N} \cdot \overline{y}_k$$,

where $N_k$ is the number of cases within a condition.

Sum of Squares:

$$SS_T = SS_B + SS_W$$

$SS_T$ = total sum of squares; represents the total variation of the data which can be decomposed $$SS_T = \Sigma_{k=1}^{K} \Sigma_{n=1}^{N} (y_{kn} - \overline{y})^2$$

$SS_B$ = between sum of squares; represents the variation between conditions $$SS_B = \Sigma_{k = 1}^K ~~ N_j \cdot (\overline{y}_k - \overline{y})^2$$

$SS_W$ = within sum of squares; represents the variation within conditions $$SS_W = \Sigma_{k = 1}^K \Sigma_{n = 1}^{N_j} (y_{nk} - \overline{y}_k )^2$$

In one-way ANOVA the systematic variation ($SS_B$) is of interest.

As the sum of squares $SS$ are dependent on the sample size, they have to be relativized to the degrees of freedom ($df$). In general, this results in mean squares ($MS$): $$MS_x = \frac{SS_x}{df_x}$$

For each sum of squares ($SS$) a corresponding means squares ($MS$) can be calculated: Total mean squares: $$MS_{T} = \frac{SS_T}{df_T} = \frac{\Sigma_{k=1}^{K} \Sigma_{n=1}^{N} (y_{kn} - \overline{y})^2}{N-1}$$, with

$df_T = N - 1$.

Between mean squares: $$MS_B = \frac{SS_B}{df_B} = \frac{\Sigma_{k = 1}^K ~~ N_j \cdot (\overline{y}_k - \overline{y})^2}{K-1}$$, with

$df_B = K - 1$.

Within mean squares: $$MS_W = \frac{SS_W}{df_W} = \frac{\Sigma_{k = 1}^K \Sigma_{n = 1}^{N_j} (y_{nk} - \overline{y}_k )^2}{N - K}$$, with

$df_W = N - K$.

Similar to the sum of squares ($SS$), additivity applies to the degrees of freedom ($df$): $$df_T = df_B + df_W$$.

The same does not apply for the mean squares ($MS$): $$MS_T \neq MS_B + MS_W$$ because if the null-hypothesis is true, all mean squares estimate the same, the population variance.

If the null-hypothesis is not true, $MS_B$ incorporates systematic variance. Dividing $MS_B$ by $MS_W$ results in a $F$-statistic by which it is possible to decide whether the null-hypothesis has to be rejected or not. $$F = \frac{MS_B}{MS_W}$$ The $F$ statistic has $df_B$ numerator degrees of freedom and $df_W$ denominator degrees of freedom. This empirical $F$ value can be compared to a critical $F$ value, given an $\alpha$ level, and the statistical significance can be assessed (if $F_{emp} > F_{crit}$ than the null-hypothesis has to be rejected).

An estimate of the effect is $\hat{\eta}^2$:

$\hat{\eta}^2 = \frac{SS_B}{SS_T}$. $\hat{\eta}^2}$ is the proportion of the systematic variation in the total variation and varies between 0 (no effect) and 1 (perfect effect = all variation is explained by the conditions). Numerator and denominator can be devided by the total sample size $N$ which results in the proportion of the systematic variance in the total variance (is equal to the aforementioned).

However, $\hat{\eta}^2$ is a positively biased effect measure (estimated effect is larger than the actual effect size). Accordingly, other effect measures have been developed like $\hat{\omega}^2$ or $f$: $$\hat{\omega}^2 = \frac{SS_B - (K-1) \cdot MS_W}{SS_T + MS_W}$$

$$ f = \hat{\phi} = \sqrt{\frac{\hat{\eta}^2}{1 - \hat{\eta}^2}}$$, here $\hat{\eta}^2$ can be substituted by $\hat{\omega}^2$.

In contrast to the confidence intervals for $\hat{\eta}^2$, the confidence intervals for the effect estimate $\hat{\omega}^2$ do not correspond with the null-hypothesis test.

Assumption of independent residuals: $Cov(\varepsilon_n, \varepsilon_n') = 0$; The covariance between residuals is zero.

Assumption of normally distributed and homoskedastic residuals: $\varepsilon_{nk} \sim \mathcal{N}(0, \sigma^2_\varepsilon$

There are $s$ non redundant pairs of comparison $$s = \frac{1}{2} \cdot K \cdot (K-1)$$

### Two-way ANOVA

$$SS_T = SS_A + SS_B + SS_{A \times B} + SS_W$$

In the two-way ANOVA, there are three possible effect (main effect of factor $A$, main effect of factor $B$ and interaction effect of factor $A$ and $B$). For each effect a effect measure can be estimated. This is called the non-partial effect size measure:

$$\hat{\eta}^2_p = \frac{SS_\text{Effect}}{SS_T}$$. 

$$\hat{\eta}^2_\text{Total} = \hat{\eta}^2_A + \hat{\eta}^2_B + \hat{\eta}^2_{A \times B}  $$

Size of $\hat{\eta}^2_p$ depends on how large other effects in the study are.



Another effect size measure is the partial effect size:
$$\hat{\eta}^2_{p\_\text{Effect}} = \frac{SS_\text{Effect}}{SS_\text{Effect} + SS_W}$$

partial effect sizes do not add up to the total effect



Use non-partial effect size if effect sizes should be compared to to other effects within the ANOVA.
Use partial effect size if effect size should be compared to other studies.


However, like in one-way ANOVA the effect measure $\hat{\eta}^2$ overestimates the effect in the population. Similarly, the effect size measure $\hat{\omega}^2$ is a non-biased effect measure. There is also a non-partial and a partial effect measure:

$$\hat{\omega}^2_\text{Effect} = \frac{SS_\text{Effect} - df_\text{Effect} \cdot MS_W}{SS_T + MS_W}$$

$$\hat{\omega}^2_{p\_\text{Effect}} = \frac{SS_\text{Effect} - df_\text{Effect} \cdot MS_W}{SS_\text{Effect} + (N - df_\text{Effect}) \cdot MS_W} $$





## Comparing several dependent samples

To add - compound symmetry and sphericity

$$SS_T~~=~~SS_{BP}~+ \underbrace{SS_{WP}}_{SS_M + SS_R}$$ 

$SS_T$ = total sum of squares 
$SS_B$ = between participants sum of squares 
$SS_W$ = within participants sum of squares

$SS_M$ = model sum of squares (between persons sum of squares) $SS_R$ = residual sum of squares

Indices: Conditions: $k$ = 1, .., $K$ Cases: $n$ = 1, ..., $N$

$$SS_T = \Sigma_{k=1}^{K} \Sigma_{n=1}^{N} (x_{kn} - \overline{x})^2$$ $SS_T$ = Sum of squared deviations of all measurements from the grand mean.

$SS_W$ =

## Comparing independent and dependent samples
