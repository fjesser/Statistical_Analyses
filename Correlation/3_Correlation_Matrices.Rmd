---
title: "Correlation Matrices"
author: "Felix EÃŸer"
date: "4/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
Often it is of interest to get the correlations of several variables among each other and not only one correlation of one pair of variables. These correlations are often arranged in a correlation matrix. 

A correlation matrix is a $p \times p$ matrix, where $p$ denotes the number of variables. Within a correlation matrix
- correlations on the principal diagonal represent the correlation of the variable with itself which equals the variances of the variable
- correlations on the off-diagonals are correlations between variables

Usually, correlation matrices are presented in tables accompanying other descriptive statistics like the means and standard deviations of the $p$ variables. In addition, it is possible to visualize correlation matrices in several ways.

As several correlations are calculated and often tested for significance, it is often important to adjust the $p$-values of the significance tests because multiple tests are conducted. 

In the following, only the pearson correlation is used, but it is possible for all other correlations too (link to Correlation file). The pearson correlation is the most used correlation coefficient and is consequently supported the most. Therefore, convenient packages are shown as well as calculation *by hand* in a loop (link to loops) in order to obtain results for less supported correlation measures.

# Packages and data

Load the necessary packages:
```{r packages, message=FALSE}
library(correlation) # plot of correlations
library(corrplot) # plots for correlation matrix
library(kableExtra) # table output
library(qgraph) # network visualization
library(RColorBrewer) # color palettes
library(skimr) # descriptive data analysis
library(tidyverse) # data wrangling, plotting, etc.
```


Load the data used in this section and output the descriptive statistics.
```{r data}
# Load data
data_arrest <- datasets::USArrests

# Get descriptives of data
skim(data_arrest)
```

This datasets contains violent crime rates in the U.S. by state. The values represent the number of people in arrest per 100,000 residents by arrest reason as well as the percentage of the urban population. 



# Correlation matrix

There are a lot of possibilities and packages to calculate correlation matrices. Here, three approaches are shown:

1. Correlation matrix using the `{stats}` package
2. Correlation matrix using the `{correlation}` package
3. Manual creation of a correlation matrix


## Correlation matrix using the built-in `{stats}` package


Correlations built upon the covariance of two variables (see link to Correlation file). For completeness, the calculation of a covariance matrix with the `cov()` function of the `{stats}` package is provided too. 

```{r cov-matrix}
# Calculate and output covariance matrix
cov(data_arrest)
```

As easily as calculating covariance matrices, it is possible to create correlation matrices with the `{stats}` package. However, only the pearson, kendall and spearman correlation measures are possible to conduct, specifying the `method` argument. 

```{r cor-matrix-stats}
# Calculate correlation matrix with stats package
cor_stats <- cor(data_arrest,
                 method = "pearson") # default; kendall or spearman possible

# Output correlation matrix
cor_stats
```

As can be seen, the correlation matrix does not provide $p$-values in order to assess the significance of the correlation. Logically, other packages have been developed in order to overcome this shortage. 

## Correlation matrix using the `{correlation}` package

The `correlation()` function of the `{correlation}` package provides several correlation measures, specified by the `method` argument (see also link to Correlation file).

```{r cor-matrix-correlation}
# Calculate correlations with correlation package
cor_correlation <- correlation(data_arrest,
                               method = "pearson", # default: pearson
                               p_adjust = "none") # default: holm

# Get full correlation as matrix
summary_correlation <- summary(cor_correlation,
                               redundant = TRUE) # default: false, get matrix 
                                                 # instead of long data form

# Output full correlation matrix
summary_correlation

```

The resulted output shows the correlation matrix with stars, indicating the level on which the correlation is significant.


## Manual creation of a correlation matrix

Although the manual creation of a correlation matrix is more cumbersome, this procedure is sometimes necessary because there is no function available that creates a correlation matrix with corresponding $p$-values. An example is the function `cor.test()` of the built-in `{stats}` package. This function calculates the pearson correlation coefficient and the associated $p$-value but cannot produce a correlation matrix. The function `cor()` of the `{stats}` package can produce a correlation matrix but lacks the calculation of $p$-values. Several packages (e.g., `{correlation}`, `{Hmisc}`) are able to overcome this problem, however, when a rarely used coefficient is needed, the following approach can be used.

In this approach the pearson correlation is calculated between the variables of the `data_arrest` dataset. This happens in the following steps:

1. Subset variables of interest from dataset
2. Create empty matrices (`NA` values) for correlation coefficients and $p$-values
3. Run nested loop populating the correlation and $p$-value matrix 


```{r cor-matrix-manual}
# 1. Create dataset only with variables their correlation is of interest ----
data_arrest <- data_arrest # here no subset necessary; included for completeness

# 2. Create matrix with NA values for correlation coefficients ----
cor_mat <- matrix(nrow = ncol(data_arrest), # pxp matrix with NA values
                  ncol = ncol(data_arrest), # p = number of variables in df
                  dimnames = list(colnames(data_arrest), colnames(data_arrest)))
# Create matrix with NA values for p-values
p_mat <- cor_mat

# 3. Nested loop to populate matrix entries ----
for (i in seq(ncol(data_arrest))) { # first loop over variables
  for (j in seq(ncol(cor_mat))) { # second loop over variables
    
    # Create temporary correaltion coefficient with p-value
    cor_temp <- cor.test(data_arrest[,i], data_arrest[,j]) 
    # Extract correlation coefficient and p-value
    cor_mat[i,j] <- cor_temp$estimate
    p_mat[i,j] <- cor_temp$p.value
    
  }
}
```

Depending on the correlation function of interest, the content of the nested loop has to be altered. 

The correlation coefficients are stored in the object `cor_mat`.

```{r cor-matrix-manual-cor}
# Output correlation matrix
cor_mat
```

The corresponding $p$-values are stored in the object `p_mat`. These $p$-values are not adjusted. See section $p$-value adjustment (insert link).

```{r cor-matrix-manual-p}
# Output of corresponding p-values
p_mat
```



# $p$-value adjustment

There are a lot of packages providing $p$-value adjustment, like `{correlation}`, `{TestCor}` or `{psych}`. Here, $p$-value adjustment is shown via the `{correlation}` package as it supports a lot of different correlation measures. Additionally, a manual way of adjusting $p$-values is shown in order to have a versatile and fail-safe approach if an correlation measure of interest is not supported. 

The available adjustment methods for the following presented procedures with the `{correlation}` package and the `p.adjust()` function of the `{stats}` package are:

1. bonferroni
2. holm
3. hochberg
4. hommel
5. BH or fdr 
6. BY
8. somers (only in the `{correlation}` package)


For the theory of $p$-value adjustment and which adjustment procedure to choose, have a look at the file `Multiple_Testing` (insert link to multiple testing).


## $p$-value adjustment with the `{correlation}` package

The `correlation()` function of the `{correlation}` package provides several options to adjust the p-values for multiple testing. 

```{r p-adj-correlation-1}
# Get correlations with corrected p-values
padj_correlation <- correlation(data_arrest,
                                p_adjust = "BH") # default
padj_correlation

# Get summary object of correlations for matrix format
summary_padj_correlation <- summary(padj_correlation,
                                    redundant = TRUE) # get full matrix

# Output correlation matrix
summary_padj_correlation
```
You could also output the object `padj_correlation` which will output a tabular format where each row represents a correlation that will show also the adjusted $p$-values. 

For the matrix of adjusted $p$-values, execute the following. 

```{r p-adj-correlation-2}
# Get matrix of adjusted p-values from correlation package
attr(summary_padj_correlation, "p")
```


## Manual $p$-value adjustment

If the matrix of $p$-values can only be obtained manually (see link to Manual creation of a correlation matrix), a manual adjustment of $p$-values is necessary. At first it is important to select only the unique $p$-values as a correlation matrix involves each correlation twice (lower and upper triangle) as well as the principal diagonal.

```{r p-adj-manual}
# Get unique p-values
p_unique <- p_mat[lower.tri(p_mat)] # values are extracted columnwise

# Adjust p-values
p_adj <- p.adjust(p_unique, 
             method = "bonferroni")

# Transform values back to matrix form
# Create empty matrix with NA
p_mat_adj <- matrix(nrow = nrow(p_mat),
                    ncol = ncol(p_mat)) 
# Fill in values in lower triangle
p_mat_adj[lower.tri(p_mat_adj)] <- p_adj 
# Fill in values for uppert triangle using transpose for correct ordering
p_mat_adj[upper.tri(p_mat_adj)] <- t(p_mat_adj)[upper.tri(p_mat_adj)]
# Set p-values in principal diagonal to 0
diag(p_mat_adj) <- 0


# Output adjusted 
p_mat_adj
```



# Tables

Outputting publication ready correlation tables is not that easy in `R` because assigning stars indicating the significance of a correlation coefficient is not supported by any package for all possible correlation measures. Therefore, the following code shows a versatile approach to produce correlation tables for any given correlation matrix. This is accomplished by means of the package `{kableExtra}`

```{r cor-table}
# 1. Data Managing ----
# Save correlations as matrix in separate object
# if manually calculated correlation matrix is used: cor_table <- cor_mat
cor_table <- summary_correlation[, -1] %>% # discard 1. column (Parameter)
  as.matrix() # save as matrix

# Save p-values as matrix in separate object
# Extracting p-values from {correlation} object via attribute
# if manually calculated p-values are used: p_table <- p_mat
p_table <- attr(summary_correlation, "p")[, -1] # discard 1. column (Parameter)


# 2. Create correlation table with significance stars ----
# on the basis of matrices
cor_table <- format(cor_table, digits = 2) # round and change to character class

# Set * for .01 > p <= .05
cor_table[p_table > .01 & p_table <= .05] <- 
  paste0(cor_table[p_table > .01 & p_table <= .05], "*")
# Set ** for .001 > p <= .01
cor_table[p_table > .001 & p_table <= .01] <- 
  paste0(cor_table[p_table > .001 & p_table <= .01], "**")
# Set *** for p <= .001
cor_table[p_table <= .001] <- paste0(cor_table[p_table <= .001], "***")

# Format table
# Set em-dash in diagonal
diag(cor_table) <- "---" # 1, SD, alpha, etc. also possible
# Set empty string in upper triangle
cor_table[upper.tri(cor_table)]  <- "" # second sample cor. also possible
# Remove zero before ".xx"
cor_table <- gsub("^0", "", cor_table)

# Rename rownames and columnnames (can also respecifed in kbl() below)
rownames(cor_table) <- colnames(cor_table)
colnames(cor_table) <- 1:ncol(cor_table)


# 3. Create full table with means and sd as 1. and 2. column ----
# if you don't want these columns, remove them at the end
# Calculate mean and sd
descriptives <- cbind(Mean = apply(data_arrest, 2, mean, na.rm = TRUE),
                      SD = apply(data_arrest, 2, sd, na.rm = TRUE))

# Transform into character
descriptives <- format(descriptives, digits = 2,
                       nsmall = 2) # minimum number of digits after decimal

# Merge descriptives with cor_table into full_table
full_table <- merge(descriptives, cor_table, by = "row.names", sort = FALSE)
# Order full_table according to cor_table (respects different ordering to desc.)
full_table <- full_table[match(rownames(cor_table), full_table$Row.names), ]

# Rename "Row.names" column to "Variable"
names(full_table)[1] <- "Variable" # Row.names added by merge()

# Add "1. " etc. in front of variable names actual rownames from "1" to "1."
full_table$Variable <- paste0(1:nrow(full_table), # row numbers
                              "\\. ", # \\ to get correct alignment in knitr
                                      # escape interpretation as numbered list
                              full_table$Variable)

# Change font of header columns "Mean" and "SD" to italic (kableExtra function)
names(full_table)[2:3] <- cell_spec(names(full_table)[2:3], italic = TRUE)


# 4. Create output table ----
# Create footnote in html-style
footnote_html <- paste("  * <i>p</i> < .05, ** <i>p</i> < .01, *** <i>p</i> < .001; <i>N</i> =", nrow(data_arrest))
#Create output table
output_table <- 
  full_table %>% 
  kbl(escape = FALSE) %>% # in order that cell_spec() specification works
  kable_classic(full_width = TRUE) %>% # default: T
  footnote(general_title = "Note: ",
           footnote_as_chunk = TRUE, # no linebreak after "Note:"
           general = footnote_html,
           escape = FALSE) # in order that html markup can be used


# 5. Output output table
# If pairwise deletion is used add another column (n) as second 
output_table

```

By aid of the package `{apaTables}` it is possible to output correlation tables in APA format into a word document using the function `apa.cor.table()`. However, as word is not open source and not as easily assimilable into a reproducible research process, it is just mentioned here for people who could be interested in it.

# Visualization

There are a lot of plot possibilities. Visualizations come to shine especially with large correlation matrices.

In addition it is also advisable to look at the univariate and bivariate distributions, see exploratory data analysis (link)

## Symbolic number encoding

`symnum()` function of the `{stats}` package. 

```{r}
# correlation matrix
cor_stats <- cor(data_arrest)

# symnum plot
symnum(cor_stats) # see argument "cutpoints" and "symbol" for customization
```

## Correlogram

Using the `{corrplot}` package. Uses the `base R` plotting system. There is also a similar package called `{ggcorrplot}` using `{ggplot2}` as a plotting system, however, this package has a lot of less customization options. 

In total, there are seven visualization methods: 
1. circle (default)
2. square
3. ellipse
4. number
5. pie
6. shade
7. color

At first, the default output of the `corrplot()` function is presented.
```{r correlogram-default}
# correlation matrix
cor_stats <- cor(data_arrest)

# Correlogram with circles
# if matrix is calculated manually add "is.corr = FALSE" 
cor_circle_plot <- corrplot(cor_stats) 
```
The size of the circles as well as their color represent the size of the correlation. 

There are a lot of customization options to change the appearance of the plot. Take a look in the documentation. Beside other customization options, the following plot orders the correlations based on an algorithm. This is especially useful for large correlation matrices to detect correlation patterns. The following algorithms can be used:
1. original (none)
2. AOE (angular order of the eigenvectors)
3. FPC (first principal component order)
4. hclust (hierarchical clustering order)
    + There are 9 different agglomeration methods for the hclust method. See the documentation for details.
    + Along with this method, rectangles can be drawn according the the hierarchical clustering. Specify the argument `addrect`
5. alphabet

The next code calculates the new plot using a bunch of, but not all (!), customization options.

At first a color palette is defined using the `colorRampPalette()` function of the built-in `{grDevices}` package. It is also possible to use the built-in color palettes of the `{grDevice}` package: `cm.colors()`, `topo.colors()`, `terrain.colors()`, `heat.colors()` or `rainbow()`, which all take an integer as argument.

```{r correlogram-customized}
# Create own color spectrum
#color_spectrum <- color

# Create customized correlogram
corrplot(cor_stats, # if matrix is calculated manually add "is.corr = FALSE" 
         # General corrplot settings
         method = "color", # visualization method
         addgrid.col = FALSE, # remove grid
         type = "lower", # only lower triangle with main diagonale
                          # this doesn't work with addrect != NULL
         diag = TRUE, # default: T; display of principal diagonal
         bg = "white", # default: "white"; used if method = "number"
         col = brewer.pal(8, "RdBu"),  # color palette from RcolorBrewer
         addCoef.col = "black", # add coefficient (number) in black 
         
         # Clustering
         order = "hclust",
         hclust.method = "complete",
         addrect = 2, # add n rectangles representing the clustering
         rect.col = "skyblue", # color of rectangles
         rect.lwd = 2, # line width of rectangles
         
         # Text labels
         tl.pos = "lt", # default; add text left and top
         tl.srt = 0, # no rotation of upper text (0 degrees)
         tl.col = "black", # color of text labels
         tl.offset = 1, # space between text labels and matrix
         
         # Color legend
         cl.pos = "r", # default: "r"; n = none
         #cl.lim = c(-1,1), # default; limits of color label

         )
```


It is also possible to create mixed correlograms using two visualization methods:

```{r correlogram-mixed}
corrplot.mixed(cor_mat,
               lower = "ellipse", # visualization method for lower triangle
               upper = "pie" # visualization method for upper triangle
)
```



It is also possible to include the $p$-values. This can be accomplished by specifying the `p.mat` argument which takes the matrix of (adjusted) $p$-values corresponding to the correlations. There are a lot of possibilities to visualize the information of the $p$-values. For example, stars can be drawn or insiginificant correlations are crossed. In the following plot, insignificant correlations have a blank field, specifying the `sig.level` argument as well as the `insig` argument. 

```{r correlogram-p-values}
corrplot(cor_mat,
         p.mat = p_mat,
         sig.level = 0.05, # default: 0.05; can be vector if insig = "label_sig"
         insig = "blank"
)
```


## Network graph for Correlations

Another way to visualize correlations among variables are network graphs. Network graphs are great to visualize large correlation matrices. Of course there are several packages like `{qgraph}` or `{ggraph}`. Here, the function `qgraph()` of the package`{qgraph}` is presented which used the `base R` plotting system. The function takes the correaltion matrix as input and the resulting graph can be written to a file, specifying the argument `filetype` of the `qgraph()` function. 

In network graphs, variables are depicted as nodes (e.g., circles) and the correlations are depicted as edges (e.g., lines). The size of the correlation is represented by the width of the edges. By default, positive correlations are shown in green and negative correlations are shown in red. 


```{r network-1}
# Output simple network graph for correlations
qgraph(cor_mat, # correlation matrix
       graph = "cor" # no edges of variable with itself
)
```


Of course there are a lot of customization options. For example, providing a list specifying which variables group together (argument `groups`) results in colored nodes.
Here, the variables `Murder`, `Assault` and `Rape` are grouped together as they indicate a crime and the variable `UrbanPop` constitute another group which indicates a sociodemographic characteristic. The list indicates the rows (or the columns) of the correlation matrix (here `cor_mat`) that group together.

```{r network-group}
# Create list indicating groups in network plot
arrest_group <- list(Crime = c(1, 2, 4), # 1 = Murder, 2 = Assault, 4 = Rape
                     SocioDem = 3) # 3 = UrbanPop
```
This list is now specified as the `groups` argument. In addition, the argument `threshold = .1` is used, discarding all edges (lines) that represent an absolute correlation below .10 and the layout is altered with the argument `layout`.

```{r network-2}
# Output a more complex network graph for correlations
qgraph(cor_mat, # correlation matrix
       graph = "cor", # no edges of variable with itself
       groups = arrest_group,
       layout = "spring", # possible values: circle, groups, spring
       threshold = .1 # show only edges (lines) with r > |.1|
)
```

It is also possible to draw only significant paths specifying the the argument `threshold = "sig"` and providing the sample size with the argument `sampleSize`. However, this is only possible for the pearson correlation but corrections are possible.


























